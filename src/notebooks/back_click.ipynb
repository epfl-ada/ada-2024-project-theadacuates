{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import statistics\n",
    "from scipy.stats import ttest_ind\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ast\n",
    "\n",
    "os.chdir(\"/Users/rapha/EPFL/ADA/ada-2024-project-theadacuates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paths = pd.read_csv(\"data/output/base_data/all_articles_processed.csv\")\n",
    "\n",
    "df_paths['path'] = df_paths['path'].str.split(';')\n",
    "\n",
    "df_pf = df_paths.loc[df_paths[\"finished\"] == True]\n",
    "df_uf = df_paths.loc[df_paths[\"finished\"] == False]\n",
    "\n",
    "cols_to_convert = [\"path_list\", \"path_list_id\", \"resolved_path_list_id\", \"resolved_path_list_name\"]\n",
    "\n",
    "for col in cols_to_convert:\n",
    "    df_paths[col] = df_paths[col].apply(ast.literal_eval)\n",
    "\n",
    "df_names = pd.read_csv(\"data/output/base_data/articles_processed.csv\")\n",
    "\n",
    "df_paths.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difficulty rating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axs = sns.barplot(data=df_pf, x='rating', y='n_back')\n",
    "axs.set_title('Number of back clicks for difficulty rating')\n",
    "axs.set_xlabel('Difficulty rating')\n",
    "axs.set_ylabel('Number of back clicks')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How far was the player when back clicking (using bfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bfs_matrix_path = \"data/output/base_data/bfs_matrix.csv\"\n",
    "bfs_matrix = pd.read_csv(bfs_matrix_path, sep=',', header=0, comment='#', index_col=\"article_name\")\n",
    "\n",
    "# returns shortest path distance between two articles, nan if cannot find the articles or no path exists\n",
    "\n",
    "def ShortestPath(article_from, article_to):\n",
    "    try:\n",
    "        return bfs_matrix[article_from][article_to]\n",
    "    except:\n",
    "        print(\"Cannot find from\", article_from, \"to\", article_to)\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a row, generates the list of distance in clicks to target from each article in path\n",
    "\n",
    "def CreateDistanceList(row):\n",
    "    path_list = row.resolved_path_list_name\n",
    "    back_click_distance = []\n",
    "\n",
    "    for article in path_list:\n",
    "        shortest_path = ShortestPath(article, row.target_link)\n",
    "    \n",
    "        back_click_distance.append(shortest_path)\n",
    "    \n",
    "    return back_click_distance\n",
    "\n",
    "df_paths[\"path_distance\"] = df_paths.apply(lambda row: CreateDistanceList(row), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a row, generates the distance to the target in order of each back click(only takes first backclick when multiple in a row)\n",
    "\n",
    "def CreateBackClickDistanceList(row):\n",
    "    path_list = row.path_list\n",
    "    back_click_distance = []\n",
    "\n",
    "    for i in range(len(path_list) - 1):\n",
    "        if path_list[i + 1] == \"<\" and path_list[i] != \"<\": # Ignore back clicks after the first one in a chain\n",
    "            shortest_path = ShortestPath(path_list[i], row.target_link)\n",
    "            back_click_distance.append(shortest_path)\n",
    "    \n",
    "    return back_click_distance\n",
    "\n",
    "df_paths[\"back_click_distance\"] = df_paths.apply(lambda row: CreateBackClickDistanceList(row), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of back click sequences, multiple back clicks in a row count as 1, matches length of back_click_distances\n",
    "\n",
    "df_paths[\"back_click_sequences\"] = df_paths.apply(lambda row: len(row.back_click_distance), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put all distances in a list\n",
    "\n",
    "distances_uf = sum(df_paths[df_paths[\"finished\"] == False][\"back_click_distance\"].tolist(), [])\n",
    "distances_uf = [x for x in distances_uf if x > 0]\n",
    "\n",
    "distances_pf = sum(df_paths[df_paths[\"finished\"] == True][\"back_click_distance\"].tolist(), [])\n",
    "distances_pf = [x for x in distances_pf if x > 0]\n",
    "\n",
    "# get mean of those distances\n",
    "print(\"Average distance from back click to target(for unfinished paths): {:.3f}\".format(statistics.mean(distances_uf)))\n",
    "print(\"Average distance from back click to target(for finished paths): {:.3f}\".format(statistics.mean(distances_pf)))\n",
    "pval = ttest_ind(distances_pf, distances_uf).pvalue\n",
    "print(\"P-value = {} so result is significant\".format(pval))\n",
    "\n",
    "# convert 0s to nans so don't get counted in mean\n",
    "bfs_matrix_nan = bfs_matrix.copy()\n",
    "bfs_matrix_nan[bfs_matrix_nan == 0] = np.nan\n",
    "matrix_mean = np.nanmean(bfs_matrix_nan)\n",
    "print(\"Average distance from any article to any other article: {:.3f}\".format(matrix_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_freq = pd.DataFrame()\n",
    "\n",
    "# distances_all = sum(df_paths[\"path_distance\"].tolist(), [])\n",
    "# distances_all = [x for x in distances_all if x > 0]\n",
    "\n",
    "# dfs = {\"back click unfinished\": distances_uf, \"back click finished\": distances_pf, \"entire path\": distances_all}\n",
    "dfs = {\"back click unfinished\": distances_uf, \"back click finished\": distances_pf}\n",
    "\n",
    "for origin, df in dfs.items():\n",
    "    labels, counts = np.unique(df, return_counts=True)\n",
    "    freq = counts / counts.sum()\n",
    "    df_temp = pd.DataFrame()\n",
    "    df_temp[\"distance\"] = labels\n",
    "    df_temp[\"frequency\"] = freq\n",
    "    df_temp[\"origin\"] = origin\n",
    "    df_combined_freq = pd.concat([df_combined_freq, df_temp.reset_index()], ignore_index=True)\n",
    "\n",
    "axs = sns.barplot(data=df_combined_freq, x='distance', y='frequency', hue=\"origin\", errorbar=None)\n",
    "axs.set_title('Distance(bfs) to target')\n",
    "axs.set_xlabel('Distance in clicks')\n",
    "axs.set_ylabel(\"Frequency\")\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "model.similarity_fn_name = \"cosine\" # valid options are “cosine”, “dot”, “euclidean”, and \"manhattan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix_path = \"data/output/semantic_similarity_data/similarity_matrix.csv\"\n",
    "\n",
    "def clamp(n, min, max): \n",
    "    if n < min: \n",
    "        return min\n",
    "    elif n > max: \n",
    "        return max\n",
    "    else: \n",
    "        return n \n",
    "\n",
    "if not os.path.exists(similarity_matrix_path):\n",
    "    embeddings = model.encode(df_names[\"article_name\"])\n",
    "    num_articles = len(embeddings)\n",
    "    matrix = np.zeros(shape=(num_articles, num_articles))\n",
    "\n",
    "    for i in range (0, num_articles):\n",
    "        similarities = model.similarity([embeddings[i]], embeddings[0:(i+1)])[0]\n",
    "        for j in range(0, i+1):\n",
    "            similarity = clamp(similarities[j], 0, 1)\n",
    "            matrix[i][j] = similarity\n",
    "            if i != j:\n",
    "                matrix[j][i] = similarity\n",
    "\n",
    "    matrix = pd.DataFrame(matrix, index = df_names[\"article_name\"], columns=df_names[\"article_name\"])\n",
    "    matrix.to_csv(similarity_matrix_path)\n",
    "\n",
    "similarity_matrix = pd.read_csv(similarity_matrix_path, sep=',', header=0, comment='#', index_col=\"article_name\")\n",
    "\n",
    "def SemanticSimilarity(article_from, article_to):\n",
    "    try:\n",
    "        return similarity_matrix[article_from][article_to]\n",
    "    except:\n",
    "        print(\"Cannot find simlarity between\", article_from, \"and\", article_to)\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateBackClickSemanticSimilarityList(row):\n",
    "    path_list = row.path_list\n",
    "    back_click_similarity = []\n",
    "\n",
    "    for i in range(len(path_list) - 1):\n",
    "        if path_list[i + 1] == \"<\" and path_list[i] != \"<\":\n",
    "            similarity = SemanticSimilarity(path_list[i], row.target_link)\n",
    "            back_click_similarity.append(similarity)\n",
    "    \n",
    "    return back_click_similarity\n",
    "\n",
    "\n",
    "df_paths[\"back_click_similarity\"] = df_paths.apply(lambda row: CreateBackClickSemanticSimilarityList(row), axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does semantic similarity to target evolve with each back click?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_backclicks = 10\n",
    "\n",
    "similarities = df_paths.loc[df_paths[\"back_click_sequences\"] >= num_backclicks][\"back_click_similarity\"].to_list()\n",
    "similarities = [x[:num_backclicks] for x in similarities]\n",
    "similarities = np.array(similarities)\n",
    "\n",
    "similarities_df = pd.DataFrame()\n",
    "similarities_df[\"mean_similarity\"] = np.mean(similarities, axis=0)\n",
    "similarities_df[\"std_similarity\"] = np.std(similarities, axis=0)\n",
    "\n",
    "\n",
    "# plt.errorbar(similarities_df.index, similarities_df.mean_similarity, yerr = similarities_df.std_similarity, capsize= 3)\n",
    "plt.plot(similarities_df.index, similarities_df.mean_similarity)\n",
    "ax = plt.gca()\n",
    "ax.set_ylim([0, 0.5])\n",
    "plt.xlabel('Back click')\n",
    "plt.ylabel('Semantic similarity')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When do back clicks happen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "entropy, connectivity, n th article (compare to average finished path length), semantic similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_back_click_pos = df_paths.loc[df_paths[\"n_back\"] >= 1][\"path_list\"].apply(lambda path: path.index(\"<\")).mean()\n",
    "\n",
    "target_pos_mean = df_paths.loc[df_paths[\"finished\"] == True][\"n_click\"].mean()\n",
    "\n",
    "print(\"Mean position of target: %.2fth article, Mean first back click position: %.2fth article\" % (target_pos_mean, first_back_click_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fatigue = pd.read_csv(\"data/output/fatigue_metric_data/articles_fatigues_long.csv\")\n",
    "\n",
    "df_fatigue.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paths['path_Readability Consensus'] = df_paths['resolved_path_list_id'].apply(lambda x: df_fatigue[\"Readability Consensus\"].iloc[x].tolist())\n",
    "df_paths['mean_path_Readability Consensus'] = df_paths['path_Readability Consensus'].apply(lambda x: np.mean(x))\n",
    "\n",
    "df_paths.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list of first article back clicked on\n",
    "first_back_click_articles = df_paths.loc[df_paths[\"n_back\"] >= 1][\"path_list\"].apply(lambda path: path[path.index(\"<\") - 1]).tolist()\n",
    "# get readability of these articles\n",
    "back_click_readability = [df_fatigue.loc[df_fatigue[\"article_name\"] == article][\"Readability Consensus\"].tolist() for article in first_back_click_articles]\n",
    "# flatten list\n",
    "back_click_readability = [\n",
    "    x\n",
    "    for xs in back_click_readability\n",
    "    for x in xs\n",
    "]\n",
    "back_click_readability_mean = np.mean(back_click_readability)\n",
    "\n",
    "# get list of readability of all articles in all paths\n",
    "all_readability = df_paths[\"path_Readability Consensus\"].tolist()\n",
    "# flatten list\n",
    "all_readability = [\n",
    "    x\n",
    "    for xs in all_readability\n",
    "    for x in xs[:-1]\n",
    "]\n",
    "all_readability_mean = np.mean(all_readability)\n",
    "\n",
    "pvalue = ttest_ind(back_click_readability, df_fatigue[\"Readability Consensus\"].tolist(), equal_var=False).pvalue\n",
    "\n",
    "print(\"Mean readbility of articles in path: %.2f  Mean readability of back clicked articles: %.2f\" % (all_readability_mean, back_click_readability_mean))\n",
    "print(\"p-value: {} so result is significant\".format(pvalue))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
