
<!-- Include MathJax -->
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<!-- Section 1: Spotlight Section -->
<section class="spotlight style1 orient-right content-align-left image-position-center onscroll-image-fade-in" id="first">
<div class="content">
    <h2>Dr. Cajal's Counterargument: Entropy</h2>
    <p>Dr. Cajal grows increasingly frustrated with the weak thesis presented by Pepito and decides to launch a <strong>counterattack.</strong></p>
    <p>He is clever, he devises a plan to exploit Pepito’s own argument. He aims to turn 
       <span class="highlight"><strong>entropy</strong></span>, 
       a concept that should ostensibly support Pepito’s ideas, into evidence that will ultimately discredit him.</p>
    <!-- <blockquote class="quote">
        "In the world of arguments, the cleverest tactic is to wield your opponent's weapons against them."
    </blockquote> -->
    <ul class="actions stacked">
    </ul>
</div>
<div class="image">
    <img src="images/spotlight01.jpg" alt="Image related to entropy">
</div>
</section>

<!-- Section 2: Content and Button to Trigger Overlay -->
<section class="wrapper style1 align-center">
<div class="inner">
    <div class="content">

        <p>
            <span class="image left"><img src="images/cajal_face.png" alt="Image of Dr. Cajal" /></span>
            <strong>Dear Pepito,</strong> let’s examine a more complex metric—<strong>the entropy of a path</strong>. 
                Entropy, you could say, serves <strong>as an index of indecisiveness and uncertainty</strong>. 
                It helps us understand why some paths are abandoned mid-journey. <br>
                <strong>High entropy</strong> suggests that users are navigating across many different articles without a clear direction, likely due to <strong>cognitive overload or confusion</strong>. 
                <!-- In essence, entropy quantifies <strong>decision-making uncertainty</strong> and can act as a proxy for cognitive load, revealing the challenges that players face as they attempt to complete paths.  -->
                If this theory holds—if entropy indeed impacts gameplay—then we should observe <strong>higher average entropy per path in unfinished journeys</strong> compared to completed ones. <br>
                <strong>I will show you that this is not the case.</strong>
        </p>

        <div style="margin-bottom: 20px; margin-top: 20px; text-align: center;">
            <button data-overlay-id="entropy" class="button big wide smooth-scroll-middle">Entropy</button>
        </div>
    </div>

    <div>
        Firstly, if entropy and, thus, the consequent cognitive load play a significant role in the path and outcome of the game, I should observe that unfinished paths are correlated with paths that have higher mean entropy. 
        However, this is not the case. Using <strong>Point-Biserial Correlation</strong>, which measures the strength and direction of the relationship between a binary categorical variable and a continuous variable, the coefficient is indeed significant but not very high, just around 0.18. This implies a weak or almost negligible correlation.
    </div>

    <div>
        Secondly, if higher entropy negatively affects the game, I should observe that unfinished paths have higher entropy, i.e., they are more challenging in terms of the next article choice. 
        But again, the data refute this hypothesis.
    </div>

    <img src="images/entropy.png" alt="Image related to Entropy" style="width: 800px; height: auto; display: block; margin: 20px auto;">

    <div>
        As can be seen, the means of the two groups are indeed different (<strong>t-test p-value < 0.05</strong>). However, interestingly, this difference favors the unfinished paths. 
        Therefore, your hypothesis that higher entropy is associated with abandonment is not only incorrect but actually completely reversed. 
        <strong>People who succeed tend to follow paths with higher entropy. In essence, they are seeking complexity and struggle.</strong>
    </div>

    <div class="content">
        <p style="margin-top: 30px; margin-bottom: 80px;">
            <span class="image right"><img src="images/pepito.jpg" alt="Image of Dr. Cajal" /></span>
            Your analysis is correct, but it doesn’t quite make sense to me. 
            Based on your findings, it seems that people are <strong>intentionally seeking out articles with higher entropy</strong>, 
            almost as if they enjoy engaging with more chaotic content. 
            This is a very strange behavior, and I would appreciate it if you could explain why this happens. 
            At this moment, I remain skeptical about your conclusion.
        </p>
    </div>

</div>
</section>


<!-- Overlay -->

<div data-overlay-id="entropy" class="overlay hidden">
    <div class="modal">
        <div class="modal-content">
            <div style="overflow-y: scroll; height: 500px;">

                <h1>Shannon Entropy</h1>

                <p>
                    Entropy can be described as the level of uncertainty along a path in the game. It can be easily assumed as a good proxy for indecision or a lack of clear direction. When an article leads to multiple subsequent articles with similar probabilities, its entropy will be high. This means that when a user is on such an article, it might be difficult for them to decide where to go next.
                </p>
                
                <p>
                    Formally, we define entropy for a single article as:
                </p>
                
                <div class="formula">
                    $$ H(X) = -\sum_{i=1}^{n} p(x_i) \log_2 p(x_i) $$
                </div>
                
                <p>
                    Where:
                    <ul>
                        <li><strong>H(X)</strong> represents the Shannon entropy of the article X <strong>X</strong>.</li>
                        <li><strong>p(x<sub>i</sub>)</strong> is the the probability of transitioning to a specific subsequent article</li>
                        <li><strong>n</strong> is the total number of possible next articles.</li>
                    </ul>
                </p>
                
                <p>
                    To calculate entropy, we need probabilities that weigh each possible next article. These probabilities have been derived using data from played games rather than from the static connectivity of the articles.
                </p>
                
                <p>
                    For example, consider the article "Dante Alighieri." It has a high entropy because many different paths can be taken from it, each with similar probabilities.

                    <img src="images/dante_entropy.png" alt="Image related to Entropy" style="width: 600px;">
                </p>
                    
                <p>
                    After calculating the entropy for each article, the entropy for the entire path (i.e., the mean of the single entropies of the articles that make up the path) was determined. Pepito’s hypothesis is that paths with higher entropy are more likely to remain unfinished, suggesting that increased randomness and indecision can negatively influence a player’s experience.
                </p>

            </div>
        </div>
    </div>
</div>














<!-- JavaScript to control overlay -->
<script>
    // Function to show the specific overlay with the given ID
    function on(overlayId) {
      document.getElementById(overlayId).style.display = "flex"; // Show specific overlay
    }
    
    // Function to hide the specific overlay when clicked
    function off(overlayId) {
      document.getElementById(overlayId).style.display = "none"; // Hide specific overlay
    }
</script>

<!-- Style of overlay -->
<style>
    /* Overlay Style */
    #overlay {
        position: fixed;
        display: hidden; /* Initially hidden */
        width: 100%;
        height: 100%;
        top: 0;
        left: 0;
        background-color: rgba(0, 0, 0, 0.5); /* Semi-transparent background */
        z-index: 2;
        cursor: pointer;
        display: flex; /* Use flexbox to center content */
        justify-content: center; /* Center content horizontally */
        align-items: center; /* Center content vertically */
    }

    /* Content Box inside the overlay */
    .overlay-content {
        width: 80%;
        max-width: 800px;
        background-color: white;
        color: black;
        padding: 20px;
        border-radius: 10px;
        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
        font-family: Arial, sans-serif;
        text-align: center;
        overflow-y: auto; /* Allow scrolling if content is too large */
        max-height: 80vh; /* Limit the box height */
    }

    /* Image inside the overlay */
    .overlay-content img {
        max-width: 100%;
        height: auto;
        border-radius: 8px;
        margin-bottom: 20px;
    }

    /* Math formula styling */
    .formula {
        font-size: 24px;
        font-weight: bold;
        color: #333;
        margin-top: 10px;
    }

    /* Button Style */
    button {
        padding: 10px 20px;
        font-size: 16px;
        color: white;
        background-color: #007BFF;
        border: none;
        border-radius: 5px;
        cursor: pointer;
    }

    button:hover {
        background-color: #0056b3;
    }
</style>
